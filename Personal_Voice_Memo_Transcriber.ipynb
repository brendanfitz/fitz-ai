{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "mount_file_id": "1YOgTW3Mq8QRRTgkxZ97tysuPLfE93aRj",
      "authorship_tag": "ABX9TyNSOjg9V6AYnl9NBV3yQYXu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brendanfitz/fitz-ai/blob/main/Personal_Voice_Memo_Transcriber.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update\n",
        "!apt-get install ffmpeg -y\n",
        "!pip install torchaudio pydub"
      ],
      "metadata": {
        "id": "yv1DaU5-KdMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2BOmI7HiUMe"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import datetime as dt\n",
        "import numpy as np\n",
        "import torchaudio\n",
        "from transformers import pipeline\n",
        "from pydub import AudioSegment\n",
        "import torch\n",
        "\n",
        "audio_wd = Path('/content/drive/MyDrive/Voice Memos')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline('automatic-speech-recognition', model='openai/whisper-large-v3')"
      ],
      "metadata": {
        "id": "u0yS7-OiisMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_audio(file_path):\n",
        "  # Get the sampling rate expected by the model\n",
        "  sampling_rate = pipe.feature_extractor.sampling_rate\n",
        "\n",
        "  audio = AudioSegment.from_file(str(file_path), format=\"m4a\")\n",
        "\n",
        "  # Convert pydub AudioSegment to numpy array\n",
        "  audio_np = np.array(audio.get_array_of_samples()).astype(np.float32)\n",
        "\n",
        "  # If the audio is stereo, it will have two channels. We need to average them for the model.\n",
        "  if audio.channels == 2:\n",
        "      audio_np = audio_np.reshape((-1, 2)).mean(axis=1)\n",
        "\n",
        "  # Resample if necessary (pydub's default is often 44.1kHz, whisper needs 16kHz)\n",
        "  if audio.frame_rate != sampling_rate:\n",
        "      # Using torchaudio for resampling as it's efficient and common in audio processing pipelines\n",
        "      # Convert numpy array to torch tensor for torchaudio\n",
        "      audio_tensor = torch.from_numpy(audio_np)\n",
        "      resampler = torchaudio.transforms.Resample(orig_freq=audio.frame_rate, new_freq=sampling_rate)\n",
        "      audio_resampled = resampler(audio_tensor)\n",
        "      audio_np = audio_resampled.numpy()\n",
        "\n",
        "  return audio_np"
      ],
      "metadata": {
        "id": "8TG_BT3mKUue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for file_path in audio_wd.glob('*'):\n",
        "  try:\n",
        "    audio_np = read_audio(file_path)\n",
        "    result = pipe(audio_np, return_timestamps=True)\n",
        "  except ValueError as e:\n",
        "    file_dt = dt.datetime.fromtimestamp(file_path.stat().st_ctime)\n",
        "    print(file_path.stem)\n",
        "    raise e\n",
        "\n",
        "  print(file_path.stem)\n",
        "  print('-' * 40)\n",
        "  print(result['text'].strip())"
      ],
      "metadata": {
        "id": "MXYJxMN4j5f4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}